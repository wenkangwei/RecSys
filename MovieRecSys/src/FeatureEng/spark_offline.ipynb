{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! head -n 20 ../../data/trainingSamples.csv\n",
    "# # configure pyspark\n",
    "# import os\n",
    "# import sys\n",
    "# from datetime import datetime, date\n",
    "# import pandas as pd\n",
    "# from pyspark.sql import Row\n",
    "\n",
    "\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\"\n",
    "# os.environ['PYSPARK_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\"\n",
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.appName(\"Spark\").getOrCreate()\n",
    "\n",
    "\n",
    "# df = spark.createDataFrame([\n",
    "#     Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "#     Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "#     Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "# ])\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure pyspark\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\"\n",
    "os.environ['PYSPARK_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\"\n",
    "data_path = \"../../data/\"\n",
    "\n",
    "# Spark configuration\n",
    "conf = SparkConf().setAppName('featureEngineering').setMaster('local')\n",
    "# Create Spark instance\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## alternative way to load csv files\n",
    "#df = spark.read.format('csv').option('header',True).load(data_path+\"movies.csv\")\n",
    "movie_df = spark.read.csv(data_path+\"movies.csv\", header=True)\n",
    "movie_df.printSchema()\n",
    "movie_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- imdbId: string (nullable = true)\n",
      " |-- tmdbId: string (nullable = true)\n",
      "\n",
      "+-------+-------+------+\n",
      "|movieId| imdbId|tmdbId|\n",
      "+-------+-------+------+\n",
      "|      1|0114709|   862|\n",
      "|      2|0113497|  8844|\n",
      "|      3|0113228| 15602|\n",
      "|      4|0114885| 31357|\n",
      "|      5|0113041| 11862|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link_df = spark.read.csv(data_path+\"links.csv\", header=True)\n",
    "link_df.printSchema()\n",
    "link_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      2|   3.5|1112486027|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|     32|   3.5|1112484819|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|     50|   3.5|1112484580|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df = spark.read.csv(data_path+\"ratings.csv\", header=True)\n",
    "rating_df.printSchema()\n",
    "rating_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "|movieId|count|Percentage|\n",
      "+-------+-----+----------+\n",
      "|    296|14616|  0.012507|\n",
      "|    467|  174|   1.49E-4|\n",
      "|    829|  402|   3.44E-4|\n",
      "|    691|  254|   2.17E-4|\n",
      "|    675|    6|    5.0E-6|\n",
      "|    125|  788|   6.74E-4|\n",
      "|    800| 1609|  0.001377|\n",
      "|    944|  259|   2.22E-4|\n",
      "|    853|   20|    1.7E-5|\n",
      "|    451|  159|   1.36E-4|\n",
      "+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    337|   3.5|1094785709|\n",
      "|    11|    344|   3.5|1230783700|\n",
      "|     1|    367|   3.5|1112485980|\n",
      "|     1|     29|   3.5|1112484676|\n",
      "|     1|    589|   3.5|1112485557|\n",
      "|     1|     47|   3.5|1112484727|\n",
      "|     1|    593|   3.5|1112484661|\n",
      "|     1|    112|   3.5|1094785740|\n",
      "|     1|    919|   3.5|1094785621|\n",
      "|    11|     19|   3.5|1230783704|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_rating_count = rating_df.count()#.groupBy('movieId').\n",
    "# show percentage of each genre\n",
    "rating_df.groupBy('movieId').count().withColumn(\"Percentage\", F.round( F.col(\"count\")/total_rating_count,6)).show(10)\n",
    "rating_df.where(F.col('rating')>=3.5).orderBy('rating', ascending=True).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+-----+----------+\n",
      "|movieId|userId|rating| timestamp|count|Percentage|\n",
      "+-------+------+------+----------+-----+----------+\n",
      "|    296|     1|   4.0|1112484767|14616|  0.012507|\n",
      "|    296|     8|   5.0| 833973081|14616|  0.012507|\n",
      "|    296|    11|   3.5|1230858799|14616|  0.012507|\n",
      "|    296|    13|   5.0| 849082366|14616|  0.012507|\n",
      "|    296|    15|   3.0| 840206642|14616|  0.012507|\n",
      "|    296|    18|   4.0|1195573677|14616|  0.012507|\n",
      "|    296|    21|   5.0| 992188845|14616|  0.012507|\n",
      "|    296|    22|   5.0| 994638043|14616|  0.012507|\n",
      "|    296|    23|   5.0| 914457789|14616|  0.012507|\n",
      "|    296|    24|   5.0| 994071115|14616|  0.012507|\n",
      "|    296|    25|   4.0|1277962554|14616|  0.012507|\n",
      "|    296|    26|   5.0| 839270563|14616|  0.012507|\n",
      "|    296|    28|   5.0| 834092660|14616|  0.012507|\n",
      "|    296|    29|   5.0| 835561519|14616|  0.012507|\n",
      "|    296|    32|   5.0| 845962251|14616|  0.012507|\n",
      "|    296|    34|   3.0| 839249781|14616|  0.012507|\n",
      "|    296|    35|   5.0|1164499167|14616|  0.012507|\n",
      "|    296|    38|   1.0| 835717875|14616|  0.012507|\n",
      "|    296|    42|   4.5|1411667904|14616|  0.012507|\n",
      "|    296|    43|   4.0|1239308843|14616|  0.012507|\n",
      "+-------+------+------+----------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent = rating_df.groupBy('movieId').count().withColumn(\"Percentage\", F.round( F.col(\"count\")/total_rating_count,6))\n",
    "rating_df.join( percent, on=['movieId'], how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.createTempView(\"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|movieId|movie_genre|\n",
      "+-------+-----------+\n",
      "|      1|  Adventure|\n",
      "|      1|  Animation|\n",
      "|      1|   Children|\n",
      "|      1|     Comedy|\n",
      "|      1|    Fantasy|\n",
      "|      2|  Adventure|\n",
      "|      2|   Children|\n",
      "|      2|    Fantasy|\n",
      "|      3|     Comedy|\n",
      "|      3|    Romance|\n",
      "|      4|     Comedy|\n",
      "|      4|      Drama|\n",
      "|      4|    Romance|\n",
      "|      5|     Comedy|\n",
      "|      6|     Action|\n",
      "|      6|      Crime|\n",
      "|      6|   Thriller|\n",
      "|      7|     Comedy|\n",
      "|      7|    Romance|\n",
      "|      8|  Adventure|\n",
      "+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_genres = spark.sql(\"select movieId ,explode(split(genres, '\\\\\\\\|')) as movie_genre from movies;\")\n",
    "exploded_genres.show()\n",
    "exploded_genres.createOrReplaceTempView(\"exploded_genres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the genres amount of each movie and the total genre amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in regular expression, `\\|` means the string should match `|` .But in python , Java programming language, we need to add one more `\\` to interpret the `\\` in `\\|`. So we need `\\\\|` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------+\n",
      "|movieId|               title|splitted_genres|\n",
      "+-------+--------------------+---------------+\n",
      "|      1|    Toy Story (1995)|      Adventure|\n",
      "|      1|    Toy Story (1995)|      Animation|\n",
      "|      1|    Toy Story (1995)|       Children|\n",
      "|      1|    Toy Story (1995)|         Comedy|\n",
      "|      1|    Toy Story (1995)|        Fantasy|\n",
      "|      2|      Jumanji (1995)|      Adventure|\n",
      "|      2|      Jumanji (1995)|       Children|\n",
      "|      2|      Jumanji (1995)|        Fantasy|\n",
      "|      3|Grumpier Old Men ...|         Comedy|\n",
      "|      3|Grumpier Old Men ...|        Romance|\n",
      "+-------+--------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+------------+\n",
      "|movieId|genres_count|\n",
      "+-------+------------+\n",
      "|    364|           6|\n",
      "|    198|           6|\n",
      "|    673|           6|\n",
      "|    459|           6|\n",
      "|    595|           6|\n",
      "|    631|           6|\n",
      "|    546|           6|\n",
      "|     20|           5|\n",
      "|    709|           5|\n",
      "|    783|           5|\n",
      "|    594|           5|\n",
      "|    558|           5|\n",
      "|    258|           5|\n",
      "|     48|           5|\n",
      "|    908|           5|\n",
      "|     22|           5|\n",
      "|    380|           5|\n",
      "|     29|           5|\n",
      "|    519|           5|\n",
      "|    970|           5|\n",
      "+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmp = movie_df.withColumn(\"splitted_genres\",F.explode(F.split(movie_df['genres'], \"\\\\|\"))).drop(\"genres\")\n",
    "tmp.show(10)\n",
    "tmp.groupBy([\"movieId\"]).agg(F.count(F.lit(\"splitted_genres\")).alias(\"genres_count\")).orderBy(F.col('genres_count'), ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the total amount of movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.select(\"splitted_genres\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert multiple genres to Multi-OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+---------+--------+------+-----+-----------+-----+-------+---------+------+----+-------+-------+-------+------+--------+---+-------+\n",
      "|movieId|Action|Adventure|Animation|Children|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|IMAX|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|\n",
      "+-------+------+---------+---------+--------+------+-----+-----------+-----+-------+---------+------+----+-------+-------+-------+------+--------+---+-------+\n",
      "|    467|     0|        0|        0|       0|     1|    0|          0|    0|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    829|     0|        0|        0|       0|     1|    0|          0|    0|      1|        0|     0|   0|      1|      0|      0|     0|       0|  0|      0|\n",
      "|    296|     0|        0|        0|       0|     1|    1|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|    675|     1|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|    691|     0|        0|        0|       0|     1|    0|          0|    0|      0|        0|     0|   0|      0|      0|      1|     0|       0|  0|      0|\n",
      "|    451|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      1|      1|     0|       0|  0|      0|\n",
      "|    944|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    800|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      1|      0|     0|       0|  0|      1|\n",
      "|    853|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    125|     0|        0|        0|       0|     1|    0|          0|    0|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    666|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      1|     0|       0|  1|      0|\n",
      "|    870|     0|        0|        0|       0|     1|    0|          0|    0|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    919|     0|        1|        0|       1|     0|    0|          0|    0|      1|        0|     0|   0|      1|      0|      0|     0|       0|  0|      0|\n",
      "|    926|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|    591|     1|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|     51|     1|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|    124|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|      7|     0|        0|        0|       0|     1|    0|          0|    0|      0|        0|     0|   0|      0|      0|      1|     0|       0|  0|      0|\n",
      "|    447|     0|        0|        0|       0|     1|    0|          0|    0|      0|        0|     0|   0|      0|      0|      1|     0|       0|  0|      0|\n",
      "|    307|     0|        0|        0|       0|     0|    0|          0|    1|      0|        0|     0|   0|      0|      0|      0|     0|       0|  0|      0|\n",
      "+-------+------+---------+---------+--------+------+-----+-----------+-----+-------+---------+------+----+-------+-------+-------+------+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.groupBy(\"movieId\").pivot(\"splitted_genres\").count().fillna(0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering\n",
    "### 1.1 Raw Data\n",
    "#### Moive\n",
    "+ movieId\n",
    "+ movie_genres (concated list)\n",
    "#### User\n",
    "+ userId\n",
    "+ user_movie_rating\n",
    "+ timestamp of rating\n",
    "\n",
    "#### Other\n",
    "+  Link.csv\n",
    "    - movieId\n",
    "    - imdbId of movie\n",
    "    - tmdbId of movie\n",
    "\n",
    "### 1.2 Possible Transformed Features\n",
    "\n",
    "#### Moive Profile\n",
    "- movieId\n",
    "- statistic variables\n",
    "    - percentage of each movie (count of that movie / total count)\n",
    "    - Averge / median rating of each movie (if rating feature exist )\n",
    "    - variance of rating of each movie (how variant the rating would be )\n",
    "- multi-onehot genres or selected genres\n",
    "- Release Year\n",
    "- Other contents (text, image, audio, other tags)\n",
    "\n",
    "####  User Profile\n",
    "- userId\n",
    "- statistic data: it tells the personality(how often the user changes his/her preference)\n",
    "    - Percentage of the amount of movies each user watchs\n",
    "    - Averge/ median rating of each user (it tells the preference of rating of this user)\n",
    "    - Variance of rating each user gives \n",
    "    - AvergeReleaseYear: measure user's preference on release year of movie (some users like new movies while others like old movies)\n",
    "    - Release Year count\n",
    "    \n",
    "- Behavior data\n",
    "    - **The genres each user visits/likes most frequently** (we can choose top k): it tells user's daily hobbies\n",
    "    - The genres each user visits/likes recently according to timestamp:  it tells how user's prefernce changes based on given genres\n",
    "    - **The movies each user visits/likes recently**: it tells how user's prefernce changes recently based on given movies\n",
    "    - rating of users on movies\n",
    "    - Discretize rating to binary label: 1(like), 0 (dislike). If rating >3, like, otherwise, dislke\n",
    "    \n",
    "- Other contents (other tags,like membership, registration date, etc, texts/comments each user posts, images each user frequently visists, ..)\n",
    "\n",
    "#### Other Context Features\n",
    "\n",
    "+ visit time\n",
    "+ others (such as website, country, location...)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Movie Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+---------+-------------------+-----+\n",
      "|movieId|userId|rating| timestamp|movie_cnt|         Percentage|label|\n",
      "+-------+------+------+----------+---------+-------------------+-----+\n",
      "|    296|     1|   4.0|1112484767|    14616|0.01250686696821428|    1|\n",
      "|    296|     8|   5.0| 833973081|    14616|0.01250686696821428|    1|\n",
      "|    296|    11|   3.5|1230858799|    14616|0.01250686696821428|    1|\n",
      "|    296|    13|   5.0| 849082366|    14616|0.01250686696821428|    1|\n",
      "|    296|    15|   3.0| 840206642|    14616|0.01250686696821428|    0|\n",
      "|    296|    18|   4.0|1195573677|    14616|0.01250686696821428|    1|\n",
      "|    296|    21|   5.0| 992188845|    14616|0.01250686696821428|    1|\n",
      "|    296|    22|   5.0| 994638043|    14616|0.01250686696821428|    1|\n",
      "|    296|    23|   5.0| 914457789|    14616|0.01250686696821428|    1|\n",
      "|    296|    24|   5.0| 994071115|    14616|0.01250686696821428|    1|\n",
      "|    296|    25|   4.0|1277962554|    14616|0.01250686696821428|    1|\n",
      "|    296|    26|   5.0| 839270563|    14616|0.01250686696821428|    1|\n",
      "|    296|    28|   5.0| 834092660|    14616|0.01250686696821428|    1|\n",
      "|    296|    29|   5.0| 835561519|    14616|0.01250686696821428|    1|\n",
      "|    296|    32|   5.0| 845962251|    14616|0.01250686696821428|    1|\n",
      "|    296|    34|   3.0| 839249781|    14616|0.01250686696821428|    0|\n",
      "|    296|    35|   5.0|1164499167|    14616|0.01250686696821428|    1|\n",
      "|    296|    38|   1.0| 835717875|    14616|0.01250686696821428|    0|\n",
      "|    296|    42|   4.5|1411667904|    14616|0.01250686696821428|    1|\n",
      "|    296|    43|   4.0|1239308843|    14616|0.01250686696821428|    1|\n",
      "+-------+------+------+----------+---------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "def addRatingLabel(samples):\n",
    "    total_count = samples.count()\n",
    "    percentage = samples.groupBy(\"movieId\").count().withColumnRenamed(\"count\",\"movie_cnt\").withColumn(\"Percentage\",F.col(\"movie_cnt\")/total_count)\n",
    "    samples = samples.join(percentage, on=['movieId'], how='left')\n",
    "    samples = samples.withColumn(\"label\", F.when(F.col(\"rating\")>3., 1).otherwise(0))\n",
    "    return samples\n",
    "\n",
    "\n",
    "label_df = addRatingLabel(rating_df)\n",
    "label_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+---------+-------------------+-----+--------------------+----------+-----------+----------------+--------------+--------------+\n",
      "|movieId|userId|rating| timestamp|movie_cnt|         Percentage|label|              genres|genres_cnt|releaseYear|movieRatingCount|movieAvgRating|movieStdRating|\n",
      "+-------+------+------+----------+---------+-------------------+-----+--------------------+----------+-----------+----------------+--------------+--------------+\n",
      "|    296|     1|   4.0|1112484767|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|     8|   5.0| 833973081|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    11|   3.5|1230858799|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    13|   5.0| 849082366|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    15|   3.0| 840206642|    14616|0.01250686696821428|    0|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    18|   4.0|1195573677|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    21|   5.0| 992188845|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    22|   5.0| 994638043|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    23|   5.0| 914457789|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "|    296|    24|   5.0| 994071115|    14616|0.01250686696821428|    1|Comedy|Crime|Dram...|         4|       1994|           14616|          4.17|          0.98|\n",
      "+-------+------+------+----------+---------+-------------------+-----+--------------------+----------+-----------+----------------+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "def extractReleaseYearUdf(title):\n",
    "    # add realease year\n",
    "    if not title or len(title.strip()) < 6:\n",
    "        return 1990\n",
    "    else:\n",
    "        yearStr = title.strip()[-5:-1]\n",
    "    return int(yearStr)\n",
    "\n",
    "\n",
    "def addMovieFea(movie_fea, rating_fea,round_num=2, use_MultiOneHot = False):\n",
    "    #first use regular expression to convert list of genres to a list\n",
    "    # then use explode function to expand the list\n",
    "    \n",
    "    # convert movie feature to onehot if enabled\n",
    "    genres_cnt = movie_fea.withColumn(\"splitted_genres\",F.explode(F.split(F.col('genres'), \"\\\\|\"))).groupBy('movieId').count()\n",
    "    genres_cnt = genres_cnt.withColumnRenamed(\"count\", \"genres_cnt\")\n",
    "    \n",
    "    movie_fea = movie_fea.join(genres_cnt, on=\"movieId\", how=\"left\")\n",
    "    \n",
    "    if use_MultiOneHot: \n",
    "        tmp = movie_fea.withColumn(\"splitted_genres\",F.explode(F.split(F.col('genres'), \"\\\\|\"))).drop(\"genres\")\n",
    "        multi_onehot = tmp.groupBy(\"movieId\").pivot(\"splitted_genres\").count().fillna(0)\n",
    "        # rename columns\n",
    "        for c in multi_onehot.columns:\n",
    "            if 'movie' not in c:\n",
    "                multi_onehot = multi_onehot.withColumnRenamed(c, \"genres_\"+c)\n",
    "        #multi_onehot.show()\n",
    "        samples = movie_fea.drop('genres').join(multi_onehot, on= \"movieId\", how= \"left\")\n",
    "    else:\n",
    "        samples = movie_fea.withColumn(\"movieGenre1\",F.split(F.col('genres'),\"\\\\|\")[0])\\\n",
    "                            .withColumn(\"movieGenre2\",F.split(F.col('genres'),\"\\\\|\")[1])\\\n",
    "                            .withColumn(\"movieGenre3\",F.split(F.col('genres'),\"\\\\|\")[2])\n",
    "        samples = movie_fea\n",
    "        \n",
    "    \n",
    "    samples = rating_fea.join(samples, on=['movieId'], how='left')\n",
    "    # add releaseYear,title\n",
    "    samples = samples.withColumn('releaseYear',\n",
    "                                                       F.udf(extractReleaseYearUdf, IntegerType())('title')) \\\n",
    "        .withColumn('title', F.udf(lambda x: x.strip()[:-6].strip(), StringType())('title')) \\\n",
    "        .drop('title')\n",
    "    \n",
    "    \n",
    "        \n",
    "    # compute statistic for each movie: count, avg rating, std rating\n",
    "    movie_stat = rating_fea.groupBy(\"movieId\").agg(F.count(F.lit(1)).alias(\"movieRatingCount\"), \n",
    "                                              F.format_number(F.avg(F.col(\"rating\")), round_num).alias(\"movieAvgRating\"), \n",
    "                                              F.format_number(F.stddev(F.col(\"rating\")), round_num).alias(\"movieStdRating\") ).fillna(0.)\n",
    "    movie_fea = samples.join(movie_stat, on=[\"movieId\"], how=\"left\")\n",
    "    \n",
    "    return movie_fea\n",
    "    \n",
    "    \n",
    "movie_fea = addMovieFea(movie_df, label_df,round_num=2)\n",
    "movie_fea.show(10)\n",
    "    \n",
    "# addMovieFea(movie_df, label_df,round_num=2, use_MultiOneHot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for using PySpark\n",
    "+ function().over(sql.Window.partitionBy(...).orderBy(..).rowBetween(...)): 用于新增window function的feature column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. User Features\n",
    "+ add user profile features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark import sql\n",
    "from collections import defaultdict\n",
    "\n",
    "NUMBER_PRECISION= 2\n",
    "\n",
    "def extractSortedGenres(genres_list):\n",
    "    \"\"\"\n",
    "    input: a list of concatenated genres string like [\"Action|Adventure|Sci-Fi|Thriller\", \"Crime|Horror|Thriller\"]\n",
    "    output: a list of genres sorted by frequency of genre ['Thriller','Action','Sci-Fi','Horror','Adventure','Crime']\n",
    "    example:\n",
    "        if we have a list of (genre, frequency) ,like (('Thriller',2),('Action',1),('Sci-Fi',1),('Horror', 1), ('Adventure',1),('Crime',1))\n",
    "        then we sort it in descending order and return ['Thriller','Action','Sci-Fi','Horror','Adventure','Crime']\n",
    "    \"\"\"\n",
    "    genre_ls = defaultdict(int) \n",
    "    for genres in  genres_list:\n",
    "        for genre in genres.split('|'):\n",
    "            genre_ls[genre] += 1\n",
    "    # genre_ls.item() = (key=genre, value=count)        \n",
    "    # return sorted list, not dictionary!\n",
    "    sorted_genres = sorted(genre_ls.items(), key=lambda x:x[1], reverse=True )\n",
    "    # return list of genre\n",
    "    return [ g[0] for g in sorted_genres]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def addUserFea(samplesWithMovieFea, round_number = 2):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        samplesWithMovieFea: Spark DataFrame with movie features\n",
    "        round_num: precision number \n",
    "    output:\n",
    "        dataframe with extracted user features\n",
    "    \"\"\"\n",
    "    # extract behavior features\n",
    "    extractSortedGenres_udf = F.udf(extractSortedGenres, ArrayType(StringType()))\n",
    "    # add user statistic: Rating count, AverageRating, Rating Stddev,  AverageReleaseYear, ReleaseYearStddev\n",
    "    # use window function to add new feature column and each user has the same value in this column\n",
    "    # the first line equivalent to   select count() over (partition by userId, order by timestemp)\n",
    "    \n",
    "    #    samplesWithUserFea.filter(samplesWithMovieFea['userId'] == 1).orderBy(F.col('timestamp').asc()).show(truncate=False)\n",
    "    #   samplesWithUserFea.where(F.col(\"userId\") == 2).show()\n",
    "    \n",
    "    \n",
    "    #  Behavior data:\n",
    "    #  The genres each user visits/likes most frequently (we can choose top k): it tells user's daily hobbies\n",
    "    #  The genres each user visits/likes recently according to timestamp: it tells how user's prefernce changes based on given genres\n",
    "    #  The movies each user visits/likes recently:\n",
    "    \n",
    "    \n",
    "    samples = samplesWithMovieFea.withColumn(\"userRatingCnt\", F.count(F.lit(1))\\\n",
    "                                             .over(sql.Window.partitionBy('userId')\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1))) \\\n",
    "                                 .withColumn(\"userAvgRating\", format_number(F.avg(\"rating\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number))\\\n",
    "                                 .withColumn(\"userRatingStddev\", format_number(F.stddev(\"rating\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number)) \\\n",
    "                                 .withColumn(\"userReleaseYearStddev\", format_number(F.stddev(\"releaseYear\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number)) \\\n",
    "                                 .withColumn(\"userAvgReleaseYear\", format_number(F.avg(\"releaseYear\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number).cast(IntegerType()))\\\n",
    "                                 .withColumn(\"userActiveMovies\", F.collect_list(when(F.col(\"label\")==1, F.col(\"movieId\")).otherwise(F.lit(None)))\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\") \\\n",
    "                                             .orderBy(\"timestamp\").rowsBetween(-100,-1)))\\\n",
    "                                 .withColumn(\"userRatedMovie1\", F.col(\"userActiveMovies\")[0])\\\n",
    "                                 .withColumn(\"userRatedMovie2\", F.col(\"userActiveMovies\")[1])\\\n",
    "                                 .withColumn(\"userRatedMovie3\", F.col(\"userActiveMovies\")[2])\\\n",
    "                                 .withColumn(\"userRatedMovie4\", F.col(\"userActiveMovies\")[3])\\\n",
    "                                 .withColumn(\"userRatedMovie5\", F.col(\"userActiveMovies\")[4])\\\n",
    "                                 .withColumn(\"userGenres\", extractSortedGenres_udf(F.collect_list(when(F.col('label') == 1, F.col('genres')).otherwise(F.lit(None)))\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1))))\\\n",
    "                                 .withColumn(\"userGenre1\", F.col(\"userGenres\")[0])\\\n",
    "                                 .withColumn(\"userGenre2\", F.col(\"userGenres\")[1])\\\n",
    "                                 .withColumn(\"userGenre3\", F.col(\"userGenres\")[2])\\\n",
    "                                 .withColumn(\"userGenre4\", F.col(\"userGenres\")[3])\\\n",
    "                                 .withColumn(\"userGenre5\", F.col(\"userGenres\")[4])\\\n",
    "                                 .drop(\"userActiveMovies\",\"userGenres\",\"genres\")\\\n",
    "                                 .filter(F.col(\"userRatingCnt\")>1) # remove the  users who watch movies once or even don't watch movie\n",
    "    samples.printSchema()\n",
    "    samples.show(5)\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "# def extractGenres(genres_list):\n",
    "#     '''\n",
    "#     pass in a list which format like [\"Action|Adventure|Sci-Fi|Thriller\", \"Crime|Horror|Thriller\"]\n",
    "#     count by each genre，return genre_list in reverse order\n",
    "#     eg:\n",
    "#     (('Thriller',2),('Action',1),('Sci-Fi',1),('Horror', 1), ('Adventure',1),('Crime',1))\n",
    "#     return:['Thriller','Action','Sci-Fi','Horror','Adventure','Crime']\n",
    "#     '''\n",
    "#     genres_dict = defaultdict(int)\n",
    "#     for genres in genres_list:\n",
    "#         for genre in genres.split('|'):\n",
    "#             genres_dict[genre] += 1\n",
    "#     sortedGenres = sorted(genres_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "#     return [x[0] for x in sortedGenres]\n",
    "\n",
    "\n",
    "# def addUserFeatures(samplesWithMovieFeatures):\n",
    "#     extractGenresUdf = F.udf(extractGenres, ArrayType(StringType()))\n",
    "#     samplesWithUserFeatures = samplesWithMovieFeatures \\\n",
    "#         .withColumn('userPositiveHistory',\n",
    "#                     F.collect_list(when(F.col('label') == 1, F.col('movieId')).otherwise(F.lit(None))).over(\n",
    "#                         sql.Window.partitionBy(\"userId\").orderBy(F.col(\"timestamp\")).rowsBetween(-100, -1))) \\\n",
    "#         .withColumn(\"userPositiveHistory\", reverse(F.col(\"userPositiveHistory\"))) \\\n",
    "#         .withColumn('userRatedMovie1', F.col('userPositiveHistory')[0]) \\\n",
    "#         .withColumn('userRatedMovie2', F.col('userPositiveHistory')[1]) \\\n",
    "#         .withColumn('userRatedMovie3', F.col('userPositiveHistory')[2]) \\\n",
    "#         .withColumn('userRatedMovie4', F.col('userPositiveHistory')[3]) \\\n",
    "#         .withColumn('userRatedMovie5', F.col('userPositiveHistory')[4]) \\\n",
    "#         .withColumn('userRatingCount',\n",
    "#                     F.count(F.lit(1)).over(sql.Window.partitionBy('userId').orderBy('timestamp').rowsBetween(-100, -1))) \\\n",
    "#         .withColumn('userAvgReleaseYear', F.avg(F.col('releaseYear')).over(\n",
    "#         sql.Window.partitionBy('userId').orderBy('timestamp').rowsBetween(-100, -1)).cast(IntegerType())) \\\n",
    "#         .withColumn('userReleaseYearStddev', F.stddev(F.col(\"releaseYear\")).over(\n",
    "#         sql.Window.partitionBy('userId').orderBy('timestamp').rowsBetween(-100, -1))) \\\n",
    "#         .withColumn(\"userAvgRating\", format_number(\n",
    "#         F.avg(F.col(\"rating\")).over(sql.Window.partitionBy('userId').orderBy('timestamp').rowsBetween(-100, -1)),\n",
    "#         NUMBER_PRECISION)) \\\n",
    "#         .withColumn(\"userRatingStddev\", F.stddev(F.col(\"rating\")).over(\n",
    "#         sql.Window.partitionBy('userId').orderBy('timestamp').rowsBetween(-100, -1))) \\\n",
    "#         .withColumn(\"userGenres\", extractGenresUdf(\n",
    "#         F.collect_list(when(F.col('label') == 1, F.col('genres')).otherwise(F.lit(None))).over(\n",
    "#             sql.Window.partitionBy('userId').orderBy('timestamp').rowsBetween(-100, -1)))) \\\n",
    "#         .withColumn(\"userRatingStddev\", format_number(F.col(\"userRatingStddev\"), NUMBER_PRECISION)) \\\n",
    "#         .withColumn(\"userReleaseYearStddev\", format_number(F.col(\"userReleaseYearStddev\"), NUMBER_PRECISION)) \\\n",
    "#         .withColumn(\"userGenre1\", F.col(\"userGenres\")[0]) \\\n",
    "#         .withColumn(\"userGenre2\", F.col(\"userGenres\")[1]) \\\n",
    "#         .withColumn(\"userGenre3\", F.col(\"userGenres\")[2]) \\\n",
    "#         .withColumn(\"userGenre4\", F.col(\"userGenres\")[3]) \\\n",
    "#         .withColumn(\"userGenre5\", F.col(\"userGenres\")[4]) \\\n",
    "#         .drop(\"genres\", \"userGenres\", \"userPositiveHistory\") \\\n",
    "#         .filter(F.col(\"userRatingCount\") > 1)\n",
    "#     samplesWithUserFeatures.printSchema()\n",
    "#     samplesWithUserFeatures.show(10)\n",
    "#     samplesWithUserFeatures.filter(samplesWithMovieFeatures['userId'] == 1).orderBy(F.col('timestamp').asc()).show(\n",
    "#         truncate=False)\n",
    "#     return samplesWithUserFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- movie_cnt: long (nullable = true)\n",
      " |-- Percentage: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      " |-- genres_cnt: long (nullable = true)\n",
      " |-- releaseYear: integer (nullable = true)\n",
      " |-- movieRatingCount: long (nullable = true)\n",
      " |-- movieAvgRating: string (nullable = true)\n",
      " |-- movieStdRating: string (nullable = true)\n",
      " |-- userRatingCnt: long (nullable = false)\n",
      " |-- userAvgRating: string (nullable = true)\n",
      " |-- userRatingStddev: string (nullable = true)\n",
      " |-- userReleaseYearStddev: string (nullable = true)\n",
      " |-- userAvgReleaseYear: integer (nullable = true)\n",
      " |-- userRatedMovie1: string (nullable = true)\n",
      " |-- userRatedMovie2: string (nullable = true)\n",
      " |-- userRatedMovie3: string (nullable = true)\n",
      " |-- userRatedMovie4: string (nullable = true)\n",
      " |-- userRatedMovie5: string (nullable = true)\n",
      " |-- userGenre1: string (nullable = true)\n",
      " |-- userGenre2: string (nullable = true)\n",
      " |-- userGenre3: string (nullable = true)\n",
      " |-- userGenre4: string (nullable = true)\n",
      " |-- userGenre5: string (nullable = true)\n",
      "\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|movieId|userId|rating|timestamp|movie_cnt|          Percentage|label|genres_cnt|releaseYear|movieRatingCount|movieAvgRating|movieStdRating|userRatingCnt|userAvgRating|userRatingStddev|userReleaseYearStddev|userAvgReleaseYear|userRatedMovie1|userRatedMovie2|userRatedMovie3|userRatedMovie4|userRatedMovie5|userGenre1|userGenre2|userGenre3|userGenre4|userGenre5|\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|    514| 10096|   3.0|954365410|     1038|8.882134587442818E-4|    0|         1|       1994|            1038|          3.50|          0.86|            2|         3.50|            0.71|                14.85|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    608| 10096|   3.0|954365515|     9505|0.008133399735418496|    0|         4|       1996|            9505|          4.09|          0.93|            3|         3.33|            0.58|                12.42|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|     50| 10096|   5.0|954365515|    10221|0.008746078768617827|    1|         3|       1995|           10221|          4.35|          0.75|            4|         3.25|            0.50|                11.24|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    593| 10096|   4.0|954365552|    13692|0.011716202964476596|    1|         3|       1991|           13692|          4.18|          0.85|            5|         3.60|            0.89|                10.12|              null|            858|             50|           null|           null|           null|     Crime|     Drama|   Mystery|  Thriller|      null|\n",
      "|     25| 10096|   2.0|954365571|     4684|0.004008084625007...|    0|         2|       1995|            4684|          3.69|          1.04|            6|         3.67|            0.82|                 9.06|              null|            858|             50|            593|           null|           null|     Crime|  Thriller|     Drama|   Mystery|    Horror|\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|movieId|userId|rating|timestamp|movie_cnt|          Percentage|label|genres_cnt|releaseYear|movieRatingCount|movieAvgRating|movieStdRating|userRatingCnt|userAvgRating|userRatingStddev|userReleaseYearStddev|userAvgReleaseYear|userRatedMovie1|userRatedMovie2|userRatedMovie3|userRatedMovie4|userRatedMovie5|userGenre1|userGenre2|userGenre3|userGenre4|userGenre5|\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|    514| 10096|   3.0|954365410|     1038|8.882134587442818E-4|    0|         1|       1994|            1038|          3.50|          0.86|            2|         3.50|            0.71|                14.85|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    608| 10096|   3.0|954365515|     9505|0.008133399735418496|    0|         4|       1996|            9505|          4.09|          0.93|            3|         3.33|            0.58|                12.42|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|     50| 10096|   5.0|954365515|    10221|0.008746078768617827|    1|         3|       1995|           10221|          4.35|          0.75|            4|         3.25|            0.50|                11.24|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    593| 10096|   4.0|954365552|    13692|0.011716202964476596|    1|         3|       1991|           13692|          4.18|          0.85|            5|         3.60|            0.89|                10.12|              null|            858|             50|           null|           null|           null|     Crime|     Drama|   Mystery|  Thriller|      null|\n",
      "|     25| 10096|   2.0|954365571|     4684|0.004008084625007...|    0|         2|       1995|            4684|          3.69|          1.04|            6|         3.67|            0.82|                 9.06|              null|            858|             50|            593|           null|           null|     Crime|  Thriller|     Drama|   Mystery|    Horror|\n",
      "|    457| 10096|   5.0|954365571|    10736|   0.009186762710095|    1|         1|       1993|           10736|          3.97|          0.78|            7|         3.43|            0.98|                 8.47|              null|            858|             50|            593|           null|           null|     Crime|  Thriller|     Drama|   Mystery|    Horror|\n",
      "|    541| 10096|   3.0|954365664|     6635|0.005677549420778719|    0|         3|       1982|            6635|          4.14|          0.88|            8|         3.62|            1.06|                 7.88|              null|            858|             50|            593|            457|           null|     Crime|  Thriller|     Drama|   Mystery|    Horror|\n",
      "|     32| 10351|   4.0|851791255|     9694| 0.00829512646345575|    1|         3|       1995|            9694|          3.89|          0.86|            2|         3.50|            0.71|                 0.71|              null|             25|           null|           null|           null|           null|     Drama|   Romance|      null|      null|      null|\n",
      "|      1| 10351|   4.0|851791255|    10759|0.009206443740491068|    1|         5|       1995|           10759|          3.91|          0.89|            3|         3.67|            0.58|                 0.58|              null|             25|             32|           null|           null|           null|     Drama|   Romance|   Mystery|    Sci-Fi|  Thriller|\n",
      "|      6| 10351|   4.0|851791281|     5245|0.004488130627277224|    1|         3|       1995|            5245|          3.84|          0.86|            4|         3.75|            0.50|                 0.50|              null|             25|             32|              1|           null|           null|     Drama|   Romance|   Mystery|    Sci-Fi|  Thriller|\n",
      "|    608| 10351|   5.0|851791281|     9505|0.008133399735418496|    1|         4|       1996|            9505|          4.09|          0.93|            5|         3.80|            0.45|                 0.45|              null|             25|             32|              1|              6|           null|  Thriller|     Drama|   Romance|   Mystery|    Sci-Fi|\n",
      "|    786| 10351|   3.0|851791305|     3445|0.002947876074541475|    0|         3|       1996|            3445|          3.15|          0.99|            6|         4.00|            0.63|                 0.52|              null|             25|             32|              1|              6|            608|  Thriller|     Drama|    Comedy|     Crime|   Romance|\n",
      "|     52| 10351|   4.0|851791305|     2033|0.001739631947617654|    1|         3|       1995|            2033|          3.54|          0.91|            7|         3.86|            0.69|                 0.53|              null|             25|             32|              1|              6|            608|  Thriller|     Drama|    Comedy|     Crime|   Romance|\n",
      "|     58| 10351|   5.0|851791305|     2498|0.002137531040407...|    1|         3|       1994|            2498|          3.95|          0.99|            8|         3.88|            0.64|                 0.52|              null|             25|             32|              1|              6|            608|     Drama|  Thriller|    Comedy|   Romance|     Crime|\n",
      "|    100| 10351|   3.0|851791340|      905|7.744057612365848E-4|    0|         2|       1996|             905|          3.21|          0.83|            9|         4.00|            0.71|                 0.67|              null|             25|             32|              1|              6|            608|     Drama|    Comedy|   Romance|  Thriller|     Crime|\n",
      "|    719| 10351|   3.0|851791360|     1683|0.001440138006807...|    0|         1|       1996|            1683|          2.94|          0.96|           10|         3.90|            0.74|                 0.67|              null|             25|             32|              1|              6|            608|     Drama|    Comedy|   Romance|  Thriller|     Crime|\n",
      "|    707| 10351|   3.0|851791360|     1005| 8.59975458610793E-4|    0|         3|       1996|            1005|          3.06|          0.88|           11|         3.82|            0.75|                 0.67|              null|             25|             32|              1|              6|            608|     Drama|    Comedy|   Romance|  Thriller|     Crime|\n",
      "|     26| 10351|   4.0|851791379|      581|4.971599417441501E-4|    1|         1|       1995|             581|          3.63|          0.94|           12|         3.75|            0.75|                 0.67|              null|             25|             32|              1|              6|            608|     Drama|    Comedy|   Romance|  Thriller|     Crime|\n",
      "|    832| 10351|   3.0|851791379|     3052|0.002611587163860836|    0|         2|       1996|            3052|          3.44|          0.92|           13|         3.77|            0.73|                 0.65|              null|             25|             32|              1|              6|            608|     Drama|    Comedy|   Romance|  Thriller|     Crime|\n",
      "|     85| 10351|   3.0|851791395|      592| 5.06572608455313E-4|    0|         2|       1995|             592|          3.56|          0.95|           14|         3.71|            0.73|                 0.65|              null|             25|             32|              1|              6|            608|     Drama|    Comedy|   Romance|  Thriller|     Crime|\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "addUserFea(movie_fea).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- movie_cnt: long (nullable = true)\n",
      " |-- Percentage: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      " |-- genres_cnt: long (nullable = true)\n",
      " |-- releaseYear: integer (nullable = true)\n",
      " |-- movieRatingCount: long (nullable = true)\n",
      " |-- movieAvgRating: string (nullable = true)\n",
      " |-- movieStdRating: string (nullable = true)\n",
      " |-- userRatingCnt: long (nullable = false)\n",
      " |-- userAvgRating: string (nullable = true)\n",
      " |-- userRatingStddev: string (nullable = true)\n",
      " |-- userReleaseYearStddev: string (nullable = true)\n",
      " |-- userAvgReleaseYear: integer (nullable = true)\n",
      " |-- userRatedMovie1: string (nullable = true)\n",
      " |-- userRatedMovie2: string (nullable = true)\n",
      " |-- userRatedMovie3: string (nullable = true)\n",
      " |-- userRatedMovie4: string (nullable = true)\n",
      " |-- userRatedMovie5: string (nullable = true)\n",
      " |-- userGenre1: string (nullable = true)\n",
      " |-- userGenre2: string (nullable = true)\n",
      " |-- userGenre3: string (nullable = true)\n",
      " |-- userGenre4: string (nullable = true)\n",
      " |-- userGenre5: string (nullable = true)\n",
      "\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|movieId|userId|rating|timestamp|movie_cnt|          Percentage|label|genres_cnt|releaseYear|movieRatingCount|movieAvgRating|movieStdRating|userRatingCnt|userAvgRating|userRatingStddev|userReleaseYearStddev|userAvgReleaseYear|userRatedMovie1|userRatedMovie2|userRatedMovie3|userRatedMovie4|userRatedMovie5|userGenre1|userGenre2|userGenre3|userGenre4|userGenre5|\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|    514| 10096|   3.0|954365410|     1038|8.882134587442818E-4|    0|         1|       1994|            1038|          3.50|          0.86|            2|         3.50|            0.71|                14.85|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    608| 10096|   3.0|954365515|     9505|0.008133399735418496|    0|         4|       1996|            9505|          4.09|          0.93|            3|         3.33|            0.58|                12.42|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|     50| 10096|   5.0|954365515|    10221|0.008746078768617827|    1|         3|       1995|           10221|          4.35|          0.75|            4|         3.25|            0.50|                11.24|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    593| 10096|   4.0|954365552|    13692|0.011716202964476596|    1|         3|       1991|           13692|          4.18|          0.85|            5|         3.60|            0.89|                10.12|              null|            858|             50|           null|           null|           null|     Crime|     Drama|   Mystery|  Thriller|      null|\n",
      "|     25| 10096|   2.0|954365571|     4684|0.004008084625007...|    0|         2|       1995|            4684|          3.69|          1.04|            6|         3.67|            0.82|                 9.06|              null|            858|             50|            593|           null|           null|     Crime|  Thriller|     Drama|   Mystery|    Horror|\n",
      "+-------+------+------+---------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111001"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addUserFeatures(movie_fea).show()\n",
    "samples = addUserFea(movie_fea)\n",
    "samples.sample(0.1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = samples.sample(0.1).withColumn(\"timestampLong\", F.col(\"timestamp\").cast(LongType()))\n",
    "# quantile = df.stat.approxQuantile(\"timestampLong\", [0.8], 0.05)\n",
    "# quantile.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(df.stat.approxQuantile)\n",
    "# df.repartition(5).show()\n",
    "# df.repartition(1).sample(0.0001).write.csv(\"../../data/processed_data/samples\",header=True, mode=\"overwrite\")\n",
    "# df.repartition(1).sample(0.0001).write.csv(\"../../data/samples.csv\",mode='overwrite')\n",
    "# ! rm -rf ../../data/processed_data/samples.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Concatenate features and Get training/testing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampleTrainTestData(samples, sample_rate=0.1, save_path =\"../../data/processed_data/\"):\n",
    "    \"\"\"\n",
    "    This function is to sample a small amount of samples from the huge dataset,\n",
    "    then it splits the sampled dataset according timestamp\n",
    "    For example, in a range of timestamp from 1second to 10000 second,80% samples are before 1000sec \n",
    "    and 20% samples are after 1000sec, we taks those 80% samples as training set and 20% samples as test set.\n",
    "    This simulates the real world setting: we use data collected before a date and use data collected after this date\n",
    "    to test the model.\n",
    "    \n",
    "    \"\"\"\n",
    "    samples = samples.sample(sample_rate).withColumn(\"timestamplong\", F.col(\"timestamp\").cast(LongType()))\n",
    "    # approximate 80% quantile with 0.05 tolerance\n",
    "    quantile = samples.stat.approxQuantile(\"timestamplong\", [0.8], 0.05)\n",
    "    timestamp_boundary = quantile[0]\n",
    "    training_samples = samples.where(F.col(\"timestamplong\")<=timestamp_boundary).drop(\"timestamplong\")\n",
    "    test_samples = samples.where(F.col(\"timestamplong\")>timestamp_boundary).drop(\"timestamplong\")\n",
    "    train_file = save_path + \"train.csv\"\n",
    "    test_file = save_path + \"test.csv\"\n",
    "    \n",
    "    # save files\n",
    "    # repartition(1) is to amke all saved samples in the same csv file\n",
    "    training_samples.repartition(1).write.option(\"header\",\"true\").mode(\"overwrite\").csv(train_file)\n",
    "    test_samples.repartition(1).write.option(\"header\",\"true\").mode(\"overwrite\").csv(test_file)\n",
    "    ## or equivalently\n",
    "    # training_samples.write.csv(train_file,header=True, mode=\"overwrite\")\n",
    "    # test_samples.write.csv(test_file,header=True, mode=\"overwrite\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|movieId|userId|rating| timestamp|movie_cnt|          Percentage|label|genres_cnt|releaseYear|movieRatingCount|movieAvgRating|movieStdRating|userRatingCnt|userAvgRating|userRatingStddev|userReleaseYearStddev|userAvgReleaseYear|userRatedMovie1|userRatedMovie2|userRatedMovie3|userRatedMovie4|userRatedMovie5|userGenre1|userGenre2|userGenre3|userGenre4|userGenre5|\n",
      "+-------+------+------+----------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "|     50| 10096|   5.0| 954365515|    10221|0.008746078768617827|    1|         3|       1995|           10221|          4.35|          0.75|            4|         3.25|            0.50|                11.24|              null|            858|           null|           null|           null|           null|     Crime|     Drama|      null|      null|      null|\n",
      "|    457| 10096|   5.0| 954365571|    10736|   0.009186762710095|    1|         1|       1993|           10736|          3.97|          0.78|            7|         3.43|            0.98|                 8.47|              null|            858|             50|            593|           null|           null|     Crime|  Thriller|     Drama|   Mystery|    Horror|\n",
      "|      6| 10351|   4.0| 851791281|     5245|0.004488130627277224|    1|         3|       1995|            5245|          3.84|          0.86|            4|         3.75|            0.50|                 0.50|              null|             25|             32|              1|           null|           null|     Drama|   Romance|   Mystery|    Sci-Fi|  Thriller|\n",
      "|    597|  1090|   5.0|1117853279|     7314|0.006258567665949593|    1|         2|       1990|            7314|          3.41|          0.98|            9|         1.89|            1.29|                 0.88|              null|            356|           null|           null|           null|           null|    Comedy|     Drama|   Romance|       War|      null|\n",
      "|    344|  1090|   3.0|1117853499|     8273| 0.00707918106376825|    0|         1|       1994|            8273|          2.98|          1.11|           10|         2.20|            1.57|                 1.63|              null|            356|            597|           null|           null|           null|    Comedy|   Romance|     Drama|       War|      null|\n",
      "|    671| 11332|   3.0| 940521671|     1382|0.001182573217711...|    0|         2|       1996|            1382|          3.65|          1.08|            3|         3.67|            0.58|                 2.00|              null|            589|             32|           null|           null|           null|    Sci-Fi|    Action|   Mystery|  Thriller|      null|\n",
      "|    260|  1159|   5.0|1018346602|    11958|0.010232424412007824|    1|         3|       1977|           11958|          4.19|          0.91|            9|         4.22|            1.30|                23.62|              null|            111|            965|             50|            154|            223|  Thriller|     Drama|   Mystery|     Crime|    Comedy|\n",
      "|    253| 11722|   4.0|1074385071|     6010|0.005142738812189917|    1|         2|       1994|            6010|          3.50|          0.94|            8|         4.00|            0.46|                 1.41|              null|            161|            480|            589|            364|              1|     Drama| Adventure|    Action| Animation|  Children|\n",
      "|     47| 11722|   4.0|1074385200|     9335|0.007987931249882342|    1|         2|       1995|            9335|          4.06|          0.87|           13|         3.92|            0.61|                 1.20|              null|            161|            480|            589|            364|              1|     Drama| Adventure|  Thriller|    Action|    Comedy|\n",
      "|    151| 11722|   4.0|1074385565|     2767|0.002367713526344...|    1|         4|       1995|            2767|          3.57|          0.92|           19|         3.89|            0.61|                 1.11|              null|            161|            480|            589|            364|              1|     Drama|  Thriller| Adventure|       War|    Action|\n",
      "|    595| 11888|   5.0| 845674383|     7539|0.006451099485041561|    1|         6|       1991|            7539|          3.65|          0.98|           10|         3.40|            1.07|                 2.23|              null|            296|            380|            344|            593|            588|    Comedy|  Thriller|     Crime| Adventure|     Drama|\n",
      "|    434| 11888|   2.0| 845674430|     5380|0.004603649718732405|    0|         3|       1993|            5380|          3.06|          0.92|           15|         3.53|            1.06|                 1.93|              null|            296|            380|            344|            593|            588|    Comedy|  Thriller| Adventure|     Crime|   Romance|\n",
      "|    480| 11888|   4.0| 845674430|    13033|0.011152298658780563|    1|         4|       1993|           13033|          3.67|          0.93|           18|         3.28|            1.18|                 1.78|              null|            296|            380|            344|            593|            588|    Comedy|  Thriller| Adventure|     Crime|   Romance|\n",
      "|    364| 11888|   5.0| 845674572|     8464|0.007242619185752987|    1|         6|       1994|            8464|          3.78|          0.93|           31|         3.32|            1.08|                 1.58|              null|            296|            380|            344|            593|            588|  Thriller|    Comedy|     Crime|     Drama|    Action|\n",
      "|    432| 11888|   3.0| 845674835|     2737| 0.00234204261713208|    0|         3|       1994|            2737|          2.74|          0.94|           56|         3.30|            0.93|                 1.51|              null|            296|            380|            344|            593|            588|    Comedy|     Drama|  Thriller|    Action|   Romance|\n",
      "|    848| 11888|   3.0| 859039052|      441|3.773623654202584...|    0|         1|       1996|             441|          3.67|          0.96|           99|         3.22|            0.95|                 2.61|              null|            296|            380|            344|            593|            588|    Action|     Drama|  Thriller|    Comedy| Adventure|\n",
      "|    593| 12847|   5.0| 834168070|    13692|0.011716202964476596|    1|         3|       1991|           13692|          4.18|          0.85|           15|         3.73|            0.70|                 1.95|              null|            296|            590|            588|            595|            318| Adventure|     Drama|    Comedy|  Thriller| Animation|\n",
      "|    608| 13772|   5.0| 907688795|     9505|0.008133399735418496|    1|         4|       1996|            9505|          4.09|          0.93|           15|         4.13|            1.13|                 1.32|              null|            527|            318|            296|             17|            593|     Drama|     Crime|   Romance|       War|  Thriller|\n",
      "|    307| 13772|   5.0| 907688848|     1432|0.001225358066398...|    1|         1|       1993|            1432|          3.96|          0.96|           19|         4.21|            1.03|                 1.58|              null|            527|            318|            296|             17|            593|     Drama|     Crime|  Thriller|   Romance|       War|\n",
      "|     36| 13772|   5.0| 907688881|     4547|0.003890854139605...|    1|         2|       1995|            4547|          3.94|          0.90|           22|         4.18|            1.01|                 1.52|              null|            527|            318|            296|             17|            593|     Drama|     Crime|  Thriller|   Romance|       War|\n",
      "+-------+------+------+----------+---------+--------------------+-----+----------+-----------+----------------+--------------+--------------+-------------+-------------+----------------+---------------------+------------------+---------------+---------------+---------------+---------------+---------------+----------+----------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.csv(\"../../data/processed_data/train.csv\",header=True)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Other Feature Engineering Operation in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting FeatureEng_util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile FeatureEng_util.py\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, QuantileDiscretizer, MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "def OneHotEncoding(samplesWithMovieFea):\n",
    "    \"\"\"\n",
    "    convert movieId to OneHot representation\n",
    "    \n",
    "    Note: \n",
    "        1. input column to onehot must be numeric type\n",
    "        2. onehot output column format:  (number of onehot columns, [one_hot position], [value]), or (number of onehot columns, {position:value})\n",
    "    \"\"\"\n",
    "    # convert movieId to int type\n",
    "    samplesWithMovieFea = samplesWithMovieFea.withColumn(\"movieId\", F.col(\"movieId\").cast(IntegerType()))\n",
    "    enc = OneHotEncoder(inputCol=\"movieId\", outputCol=\"movieIdVector\",dropLast=False)\n",
    "    samplesWithMovieFea = enc.fit(samplesWithMovieFea).transform(samplesWithMovieFea)\n",
    "    samplesWithMovieFea.show(5)\n",
    "    \n",
    "    return samplesWithMovieFea\n",
    "\n",
    "def Array2Vec(genreIndices, indexSize):\n",
    "    \"\"\"\n",
    "    Convert Array type feature to a vector\n",
    "    input:\n",
    "        input are the features in one row. These features include:\n",
    "            genreIndices: a list of numeric indice of genres\n",
    "            indexSize: size of index\n",
    "    output: \n",
    "        converted multi-onehot array for each row in table\n",
    "    \"\"\"\n",
    "    genreIndices.sort()\n",
    "    # a list of values to fill into muulti-one-hot array\n",
    "    fill_list = [1.0 for i in range(len(genreIndices)) ]\n",
    "    \n",
    "    # sparse take  size of vector, positions in vector to fill, values used to fill these position\n",
    "    return Vectors.sparse(indexSize, genreIndices, fill_list)\n",
    "\n",
    "\n",
    "def MultiOneHotEncoding(samplesWithMovieFea):\n",
    "    \"\"\"\n",
    "    convert genres of each movie to multi-onehot represenatation\n",
    "    Step:\n",
    "        1. first explode the genres for each movie into multiple rows\n",
    "        2. use StringIndexer to convert genres into genreIndex in numerical label format\n",
    "        3. obtain size of index\n",
    "        4. aggregate the genreIndex list to get genreIndex array list for each movie \n",
    "        5. Convert genreIndex array list into multi-onehot\n",
    "    \"\"\"\n",
    "    # split genre list for each movie and convert string to string list. Then explode each genre into one row\n",
    "    samplesWithMovieFea = samplesWithMovieFea.withColumn(\"genre\", F.explode(F.split(\"genres\",\"\\\\|\").cast(ArrayType(StringType()))))\n",
    "    # Convert string list to numerical index label list in each row\n",
    "    indexer = StringIndexer(inputCol=\"genre\",outputCol= \"genreIndex\")\n",
    "    indexModel= indexer.fit(samplesWithMovieFea)\n",
    "    samplesWithMovieFea = indexModel.transform(samplesWithMovieFea)\n",
    "    print(\"String labels: \")\n",
    "    print(indexModel.labels)\n",
    "    #indexer.save(\"StringIndices.csv\")\n",
    "    # obtain size of index and add indexSize to a new column\n",
    "    indexSize = samplesWithMovieFea.agg(F.max(\"genreIndex\")).head()[0] + 1\n",
    "    \n",
    "    samplesWithMovieFea = samplesWithMovieFea.groupBy(\"movieId\").agg(F.collect_list(\"genreIndex\").alias(\"genreIndices\"))\n",
    "    samplesWithMovieFea = samplesWithMovieFea.withColumn(\"IndexSize\", F.lit(indexSize))\n",
    "    \n",
    "    # Convert index list in each row into multi-onehot vector\n",
    "    Array2Vec_UDF = udf(Array2Vec, VectorUDT())\n",
    "    samplesWithMovieFea = samplesWithMovieFea.withColumn(\"MultiOneHot_Vector\", Array2Vec_UDF(F.col(\"genreIndices\"), F.col(\"IndexSize\")) ).orderBy(\"movieId\")\n",
    "    \n",
    "    \n",
    "    return samplesWithMovieFea\n",
    "\n",
    "\n",
    "def MultiOneHot_v2(sampleWithMovieFea):\n",
    "    \"\"\"\n",
    "    This function convert genre array list to Multi-OneHot using Pivot function\n",
    "    Use Pivot and array method to convert genres to multi-onehot, without using StringIndexer\n",
    "    \"\"\"\n",
    "    def arr2vec(arr):\n",
    "        indexSize = len(arr)\n",
    "        pos = [i for i in range(len(arr)) if arr[i]==1 ]\n",
    "        fill_ls = [1]*len(pos)\n",
    "        return Vectors.sparse(indexSize, pos, fill_ls)\n",
    "    \n",
    "    arr2vec_udf = udf(arr2vec, VectorUDT())\n",
    "    tmp = sampleWithMovieFea.withColumn(\"splitted_genres\",F.explode(F.split(F.col('genres'), \"\\\\|\"))).drop(\"genres\")\n",
    "    genre_ls = [s.splitted_genres for s in  tmp.select(\"splitted_genres\").distinct().collect()]\n",
    "    genre_ls.sort()\n",
    "    print(genre_ls )\n",
    "    \n",
    "    multi_onehot = tmp.groupBy(\"movieId\").pivot(\"splitted_genres\").count().fillna(0)\n",
    "    ##rename columns\n",
    "    #for c in multi_onehot.columns:\n",
    "    #    if 'movie' not in c:\n",
    "    #        multi_onehot = multi_onehot.withColumnRenamed(c, \"genres_\"+c)\n",
    "    #multi_onehot.show()\n",
    "    \n",
    "    columns = [F.col(c) for c in genre_ls]\n",
    "    multi_onehot = multi_onehot.withColumn(\"Genres_Vector\",arr2vec_udf(F.array(genre_ls))).drop(*genre_ls)\n",
    "    samples = sampleWithMovieFea.drop('genres').join(multi_onehot, on= \"movieId\", how= \"left\").orderBy(\"movieId\")\n",
    "    return samples\n",
    "\n",
    "def ratingDiscretizer(samplesWithRating):\n",
    "    \"\"\"\n",
    "    This function adds statistic features of rating and\n",
    "    discretize the rating feature using Binning. Then it normalize rating feature\n",
    "    using MinMaxScalar\n",
    "    \"\"\"\n",
    "    samplesWithRating.printSchema()\n",
    "    # compute statistic for each movie\n",
    "    samplesWithRating  = samplesWithRating.groupBy(\"movieId\").agg(F.avg(\"rating\").alias(\"AvgRating\"),\n",
    "                                                                  F.variance(\"rating\").alias(\"RatingVar\"),\n",
    "                                                                 F.count(F.lit(1)).alias(\"ratingCnt\"))\n",
    "    \n",
    "    # we need to convert average rating value to a dense Vector with User Define Type (UDT)\n",
    "    # udf(lambda x: Vectors.dense(x), VectorUDT()):  take  dense vector as input,  VectorUDT() type vector as output\n",
    "    samplesWithRating = samplesWithRating.withColumn('avgRatingVec', udf(lambda x: Vectors.dense(x), VectorUDT())('avgRating'))\n",
    "    print()\n",
    "    print(\"Dense Vector\")\n",
    "    samplesWithRating.show(5)\n",
    "    \n",
    "    #Bucket and discretize the rating\n",
    "    ratingDiscretizer = QuantileDiscretizer(inputCol=\"ratingCnt\", outputCol=\"ratingCntBucket\", numBuckets= 100)\n",
    "    \n",
    "    # MinMaxScaler\n",
    "    scaler = MinMaxScaler(inputCol=\"avgRatingVec\", outputCol=\"ScaledAvgRating\")\n",
    "    pipe = Pipeline(stages = [ratingDiscretizer, scaler])\n",
    "    TransformedSamples = pipe.fit(samplesWithRating).transform(samplesWithRating)\n",
    "    TransformedSamples.show(5)\n",
    "    \n",
    "    return TransformedSamples\n",
    "\n",
    "def test(data_path):\n",
    "    # Spark configuration\n",
    "    conf = SparkConf().setAppName('featureEngineering').setMaster('local')\n",
    "    # Create Spark instance\n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "    \n",
    "    movie_df = spark.read.csv(data_path+\"movies.csv\", header=True)\n",
    "    movie_df = OneHotEncoding(movie_df)\n",
    "#     movie_df = MultiOneHot_v2(movie_df)\n",
    "    movie_df = MultiOneHotEncoding(movie_df)\n",
    "    movie_df.printSchema()\n",
    "    movie_df.show(5)\n",
    "    \n",
    "    \n",
    "    #movie_df.show(5)\n",
    "    link_df = spark.read.csv(data_path+\"links.csv\", header=True)\n",
    "    link_df.printSchema()\n",
    "    #link_df.show(5)\n",
    "\n",
    "    rating_df = spark.read.csv(data_path+\"ratings.csv\", header=True)\n",
    "    rating_df.printSchema()\n",
    "    #rating_df.show(5)\n",
    "    rating_df = ratingDiscretizer(rating_df)\n",
    "    rating_df.printSchema()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     os.environ['PYSPARK_DRIVER_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\" # path to python exec file\n",
    "#     os.environ['PYSPARK_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\" #path to python exec file\n",
    "    data_path = \"../../data/\"\n",
    "    test(data_path)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write Source code to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting FeatureEngineering.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile FeatureEngineering.py\n",
    "\n",
    "# configure pyspark\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import sql\n",
    "from collections import defaultdict\n",
    "\n",
    "def addRatingLabel(samples):\n",
    "    total_count = samples.count()\n",
    "    percentage = samples.groupBy(\"movieId\").count().withColumnRenamed(\"count\",\"movie_cnt\").withColumn(\"Percentage\",F.col(\"movie_cnt\")/total_count)\n",
    "    samples = samples.join(percentage, on=['movieId'], how='left')\n",
    "    samples = samples.withColumn(\"label\", F.when(F.col(\"rating\")>3., 1).otherwise(0))\n",
    "    return samples\n",
    "\n",
    "\n",
    "\n",
    "def extractReleaseYearUdf(title):\n",
    "    # add realease year\n",
    "    if not title or len(title.strip()) < 6:\n",
    "        return 1990\n",
    "    else:\n",
    "        yearStr = title.strip()[-5:-1]\n",
    "    return int(yearStr)\n",
    "\n",
    "\n",
    "def addMovieFea(movie_fea, rating_fea,round_num=2, use_MultiOneHot = False):\n",
    "    #first use regular expression to convert list of genres to a list\n",
    "    # then use explode function to expand the list\n",
    "    \n",
    "    # convert movie feature to onehot if enabled\n",
    "    genres_cnt = movie_fea.withColumn(\"splitted_genres\",F.explode(F.split(F.col('genres'), \"\\\\|\"))).groupBy('movieId').count()\n",
    "    genres_cnt = genres_cnt.withColumnRenamed(\"count\", \"genres_cnt\")\n",
    "    \n",
    "    movie_fea = movie_fea.join(genres_cnt, on=\"movieId\", how=\"left\")\n",
    "    \n",
    "    if use_MultiOneHot: \n",
    "        tmp = movie_fea.withColumn(\"splitted_genres\",F.explode(F.split(F.col('genres'), \"\\\\|\"))).drop(\"genres\")\n",
    "        multi_onehot = tmp.groupBy(\"movieId\").pivot(\"splitted_genres\").count().fillna(0)\n",
    "        # rename columns\n",
    "        for c in multi_onehot.columns:\n",
    "            if 'movie' not in c:\n",
    "                multi_onehot = multi_onehot.withColumnRenamed(c, \"genres_\"+c)\n",
    "        #multi_onehot.show()\n",
    "        samples = movie_fea.drop('genres').join(multi_onehot, on= \"movieId\", how= \"left\")\n",
    "    else:\n",
    "        samples = movie_fea.withColumn(\"movieGenre1\",F.split(F.col('genres'),\"\\\\|\")[0])\\\n",
    "                            .withColumn(\"movieGenre2\",F.split(F.col('genres'),\"\\\\|\")[1])\\\n",
    "                            .withColumn(\"movieGenre3\",F.split(F.col('genres'),\"\\\\|\")[2])\n",
    "        samples = movie_fea\n",
    "        \n",
    "    \n",
    "    samples = rating_fea.join(samples, on=['movieId'], how='left')\n",
    "    # add releaseYear,title\n",
    "    samples = samples.withColumn('releaseYear',\n",
    "                                                       F.udf(extractReleaseYearUdf, IntegerType())('title')) \\\n",
    "        .withColumn('title', F.udf(lambda x: x.strip()[:-6].strip(), StringType())('title')) \\\n",
    "        .drop('title')\n",
    "    \n",
    "    \n",
    "        \n",
    "    # compute statistic for each movie: count, avg rating, std rating\n",
    "    movie_stat = rating_fea.groupBy(\"movieId\").agg(F.count(F.lit(1)).alias(\"movieRatingCount\"), \n",
    "                                              F.format_number(F.avg(F.col(\"rating\")), round_num).alias(\"movieAvgRating\"), \n",
    "                                              F.format_number(F.stddev(F.col(\"rating\")), round_num).alias(\"movieStdRating\") ).fillna(0.)\n",
    "    movie_fea = samples.join(movie_stat, on=[\"movieId\"], how=\"left\")\n",
    "    \n",
    "    return movie_fea\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extractSortedGenres(genres_list):\n",
    "    \"\"\"\n",
    "    input: a list of concatenated genres string like [\"Action|Adventure|Sci-Fi|Thriller\", \"Crime|Horror|Thriller\"]\n",
    "    output: a list of genres sorted by frequency of genre ['Thriller','Action','Sci-Fi','Horror','Adventure','Crime']\n",
    "    example:\n",
    "        if we have a list of (genre, frequency) ,like (('Thriller',2),('Action',1),('Sci-Fi',1),('Horror', 1), ('Adventure',1),('Crime',1))\n",
    "        then we sort it in descending order and return ['Thriller','Action','Sci-Fi','Horror','Adventure','Crime']\n",
    "    \"\"\"\n",
    "    genre_ls = defaultdict(int) \n",
    "    for genres in  genres_list:\n",
    "        for genre in genres.split('|'):\n",
    "            genre_ls[genre] += 1\n",
    "    # genre_ls.item() = (key=genre, value=count)        \n",
    "    # return sorted list, not dictionary!\n",
    "    sorted_genres = sorted(genre_ls.items(), key=lambda x:x[1], reverse=True )\n",
    "    # return list of genre\n",
    "    return [ g[0] for g in sorted_genres]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def addUserFea(samplesWithMovieFea, round_number = 2):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        samplesWithMovieFea: Spark DataFrame with movie features\n",
    "        round_num: precision number \n",
    "    output:\n",
    "        dataframe with extracted user features\n",
    "    \"\"\"\n",
    "    # extract behavior features\n",
    "    extractSortedGenres_udf = F.udf(extractSortedGenres, ArrayType(StringType()))\n",
    "    # add user statistic: Rating count, AverageRating, Rating Stddev,  AverageReleaseYear, ReleaseYearStddev\n",
    "    # use window function to add new feature column and each user has the same value in this column\n",
    "    # the first line equivalent to   select count() over (partition by userId, order by timestemp)\n",
    "    \n",
    "    #    samplesWithUserFea.filter(samplesWithMovieFea['userId'] == 1).orderBy(F.col('timestamp').asc()).show(truncate=False)\n",
    "    #   samplesWithUserFea.where(F.col(\"userId\") == 2).show()\n",
    "    \n",
    "    \n",
    "    #  Behavior data:\n",
    "    #  The genres each user visits/likes most frequently (we can choose top k): it tells user's daily hobbies\n",
    "    #  The genres each user visits/likes recently according to timestamp: it tells how user's prefernce changes based on given genres\n",
    "    #  The movies each user visits/likes recently:\n",
    "    \n",
    "    \n",
    "    samples = samplesWithMovieFea.withColumn(\"userRatingCnt\", F.count(F.lit(1))\\\n",
    "                                             .over(sql.Window.partitionBy('userId')\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1))) \\\n",
    "                                 .withColumn(\"userAvgRating\", format_number(F.avg(\"rating\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number))\\\n",
    "                                 .withColumn(\"userRatingStddev\", format_number(F.stddev(\"rating\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number)) \\\n",
    "                                 .withColumn(\"userReleaseYearStddev\", format_number(F.stddev(\"releaseYear\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number)) \\\n",
    "                                 .withColumn(\"userAvgReleaseYear\", format_number(F.avg(\"releaseYear\")\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1)), round_number).cast(IntegerType()))\\\n",
    "                                 .withColumn(\"userActiveMovies\", F.collect_list(when(F.col(\"label\")==1, F.col(\"movieId\")).otherwise(F.lit(None)))\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\") \\\n",
    "                                             .orderBy(\"timestamp\").rowsBetween(-100,-1)))\\\n",
    "                                 .withColumn(\"userRatedMovie1\", F.col(\"userActiveMovies\")[0])\\\n",
    "                                 .withColumn(\"userRatedMovie2\", F.col(\"userActiveMovies\")[1])\\\n",
    "                                 .withColumn(\"userRatedMovie3\", F.col(\"userActiveMovies\")[2])\\\n",
    "                                 .withColumn(\"userRatedMovie4\", F.col(\"userActiveMovies\")[3])\\\n",
    "                                 .withColumn(\"userRatedMovie5\", F.col(\"userActiveMovies\")[4])\\\n",
    "                                 .withColumn(\"userGenres\", extractSortedGenres_udf(F.collect_list(when(F.col('label') == 1, F.col('genres')).otherwise(F.lit(None)))\\\n",
    "                                             .over(sql.Window.partitionBy(\"userId\")\\\n",
    "                                                   .orderBy('timestamp').rowsBetween(-100,-1))))\\\n",
    "                                 .withColumn(\"userGenre1\", F.col(\"userGenres\")[0])\\\n",
    "                                 .withColumn(\"userGenre2\", F.col(\"userGenres\")[1])\\\n",
    "                                 .withColumn(\"userGenre3\", F.col(\"userGenres\")[2])\\\n",
    "                                 .withColumn(\"userGenre4\", F.col(\"userGenres\")[3])\\\n",
    "                                 .withColumn(\"userGenre5\", F.col(\"userGenres\")[4])\\\n",
    "                                 .drop(\"userActiveMovies\",\"userGenres\",\"genres\")\\\n",
    "                                 .filter(F.col(\"userRatingCnt\")>1) # remove the  users who watch movies once or even don't watch movie\n",
    "    samples.printSchema()\n",
    "    samples.show(5)\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "\n",
    "def SampleTrainTestDataByTime(samples, sample_rate=0.1, save_path =\"../../data/processed_data/\"):\n",
    "    \"\"\"\n",
    "    This function is to sample a small amount of samples from the huge dataset,\n",
    "    then it splits the sampled dataset according timestamp\n",
    "    For example, in a range of timestamp from 1second to 10000 second,80% samples are before 1000sec \n",
    "    and 20% samples are after 1000sec, we taks those 80% samples as training set and 20% samples as test set.\n",
    "    This simulates the real world setting: we use data collected before a date and use data collected after this date\n",
    "    to test the model.\n",
    "    \n",
    "    \"\"\"\n",
    "    samples = samples.sample(sample_rate).withColumn(\"timestamplong\", F.col(\"timestamp\").cast(LongType()))\n",
    "    # approximate 80% quantile with 0.05 tolerance\n",
    "    quantile = samples.stat.approxQuantile(\"timestamplong\", [0.8], 0.05)\n",
    "    timestamp_boundary = quantile[0]\n",
    "    training_samples = samples.where(F.col(\"timestamplong\")<=timestamp_boundary).drop(\"timestamplong\")\n",
    "    test_samples = samples.where(F.col(\"timestamplong\")>timestamp_boundary).drop(\"timestamplong\")\n",
    "    train_file = save_path + \"train.csv\"\n",
    "    test_file = save_path + \"test.csv\"\n",
    "    \n",
    "    # save files\n",
    "    # repartition(1) is to amke all saved samples in the same csv file\n",
    "    training_samples.repartition(1).write.option(\"header\",\"true\").mode(\"overwrite\").csv(train_file)\n",
    "    test_samples.repartition(1).write.option(\"header\",\"true\").mode(\"overwrite\").csv(test_file)\n",
    "    training_samples.toPandas().to_csv(test_file,header=True,index=False)\n",
    "    test_samples.toPandas().to_csv(test_file,header=True,index=False)\n",
    "    ## or equivalently\n",
    "    # training_samples.write.csv(train_file,header=True, mode=\"overwrite\")\n",
    "    # test_samples.write.csv(test_file,header=True, mode=\"overwrite\")\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    os.environ['PYSPARK_DRIVER_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\" # path to python exec file\n",
    "    os.environ['PYSPARK_PYTHON']=\"/home/wenkanw/.conda/envs/mlenv/bin/python3\" #path to python exec file\n",
    "    data_path = \"../../data/\"\n",
    "\n",
    "    # Spark configuration\n",
    "    conf = SparkConf().setAppName('featureEngineering').setMaster('local')\n",
    "    # Create Spark instance\n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "    \n",
    "    movie_df = spark.read.csv(data_path+\"movies.csv\", header=True)\n",
    "    movie_df.printSchema()\n",
    "    #movie_df.show(5)\n",
    "    link_df = spark.read.csv(data_path+\"links.csv\", header=True)\n",
    "    link_df.printSchema()\n",
    "    #link_df.show(5)\n",
    "\n",
    "    rating_df = spark.read.csv(data_path+\"ratings.csv\", header=True)\n",
    "    rating_df.printSchema()\n",
    "    #rating_df.show(5)\n",
    "\n",
    "    label_df = addRatingLabel(rating_df)\n",
    "    #label_df.show()\n",
    "    movie_fea = addMovieFea(movie_df, label_df,round_num=2)\n",
    "    movie_fea.show(10)\n",
    "    transformed_samples = addUserFea(movie_fea)\n",
    "    SampleTrainTestDataByTime(transformed_samples, sample_rate=0.1, save_path =\"../../data/processed_data/\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\r\n"
     ]
    }
   ],
   "source": [
    "# !python ./FeatureEngineering.py\n",
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion about some Tricks\n",
    "+ Data we can explore from raw data\n",
    "   - Atribute and Label Data       \n",
    "       - Statistic data (count, average, Stddev, etc)\n",
    "       - categorical labels (like tags)\n",
    "       - numerical features\n",
    "   - Behavior Data\n",
    "       - 0/1 like or dislike\n",
    "       - Rating\n",
    "       - favourite\n",
    "       - Sequential Data (sequence of item rated along time)\n",
    "   - Relationship Data\n",
    "       - Links among users and items in a graph \n",
    "       - Sequential Data (sequence of item rated along time), relationship among items visited by the same user\n",
    "   - Content Data\n",
    "       - Image\n",
    "       - Text\n",
    "       - Audio\n",
    "       - Video\n",
    "       - etc\n",
    "+ **Usages of some functions**\n",
    "   - Vector.sparse()\n",
    "       - We either input a list of positions and a list of values to fill in vector, or a dictionary in format {position:value}\n",
    "       - Vector.sparse(indexSize,positions_in_vector , values_to_fill_in_vector)\n",
    "       - Vector.sparse(indexSize, {position: value})\n",
    "   - Window function in Spark\n",
    "       - `withColumn(\"..\", Func(col(..)).over(sql.Window.partitionBy(col(...)).orderBy(col(..)).rowsBetween(..,..)) )` 其中 Func()可以是 sum(), count()等操作函数\n",
    "   - Save Dataframe to file\n",
    "       - `df.repartition(n).write.csv(file_name, header=True,mode='overwrite')`. \n",
    "       - .repartition(n): partition dataframe and save it into n csv files \n",
    "       - .over(...): it is equivalent to the 'over' keyword in SQL\n",
    "   - **Spark UDF** \n",
    "       -  使用Spark UDF时， UDF函数的输入是table的某个column， 输入形式是一个row， 或者如果用了collect_list()函数作为输入，输入就是一个list of rows.输出是对应那个row的新column的值\n",
    "\n",
    "\n",
    "       \n",
    "+ **Debug Notes:**\n",
    "   - 当PySpark Query很长时，尽量一句一句跑和加上去来debug，看一下有没有漏括号\n",
    "   - `sorted(dictionary, key=..)`函数返回的是一个元素格式为[key， value]的list，\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv_v2",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
